{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "dataset_df_1 = pd.read_csv('final6extension/articles_SABC_decoded_2_.tsv', sep='\\t', header=0)\n",
    "\n",
    "print(dataset_df_1.size)\n",
    "print(dataset_df_1.shape[0])\n",
    "print(dataset_df_1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_texts_list = dataset_df_1['Text'].tolist()\n",
    "print(len(col_texts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentences_1D = []\n",
    "\n",
    "limit = 2000000\n",
    "i = 0\n",
    "for article_text in col_texts_list:\n",
    "    if limit<i:\n",
    "        break\n",
    "    i +=1\n",
    "    try:\n",
    "        encoded_string = article_text.encode(\"ascii\", \"ignore\")\n",
    "        decode_string = encoded_string.decode()\n",
    "    except:\n",
    "        encoded_string = \"N/A\"\n",
    "        decode_string = \"N/A\"\n",
    "    tokens = nlp(decode_string)\n",
    "    for t in tokens.sents:\n",
    "        print (t.text.strip() , \"\\n\")\n",
    "        final_sentence = t.text.strip()\n",
    "        arr_words = final_sentence.split()\n",
    "        if len(arr_words)>2:\n",
    "            sentences.append([final_sentence ,\"\"])\n",
    "            sentences_1D.append(final_sentence)\n",
    "\n",
    "final_df = pd.DataFrame(columns=['Sentence', 'Translation'], data=sentences)\n",
    "final_1D_df = pd.DataFrame(sentences_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop_duplicates(subset=['Sentence'])\n",
    "\n",
    "final_1D_df = final_1D_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final6extension/sentences/sentences_SABC_STACY_1.tsv', sep='\\t')\n",
    "final_1D_df.to_csv('final6extension/sentences/sentences_SABC_STACY_1D.tsv', sep='\\t')\n",
    "print(\"done list of sentences..........\",i)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
